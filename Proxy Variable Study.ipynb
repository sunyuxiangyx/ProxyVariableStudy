{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1011ef29",
   "metadata": {
    "id": "1011ef29"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import normalize\n",
    "import sklearn.utils\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)\n",
    "torch.set_printoptions(precision=4)\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b8facc0",
   "metadata": {
    "id": "7b8facc0"
   },
   "outputs": [],
   "source": [
    "csv_data = pd.read_csv('application_record.csv')\n",
    "\n",
    "# Some Preprocessing\n",
    "csv_data = csv_data.drop_duplicates('ID', keep='last').copy()\n",
    "csv_data['DAYS_BIRTH'] = round(csv_data['DAYS_BIRTH']/-365,0)\n",
    "csv_data.rename(columns={'DAYS_BIRTH':'AGE_YEARS'}, inplace=True)\n",
    "csv_data['DAYS_EMPLOYED'].replace(365243, 0, inplace=True)\n",
    "csv_data['DAYS_EMPLOYED'] = abs(round(csv_data['DAYS_EMPLOYED']/-365,0))\n",
    "csv_data.rename(columns={'DAYS_EMPLOYED':'YEARS_EMPLOYED'}, inplace=True)\n",
    "csv_data.drop('FLAG_MOBIL', axis=1, inplace=True)\n",
    "\n",
    "csv_data['CODE_GENDER'].replace(\"F\", 0, inplace=True)\n",
    "csv_data['CODE_GENDER'].replace(\"M\", 1, inplace=True)\n",
    "csv_data['FLAG_OWN_CAR'].replace(\"N\", 0, inplace=True)\n",
    "csv_data['FLAG_OWN_CAR'].replace(\"Y\", 1, inplace=True)\n",
    "csv_data['FLAG_OWN_REALTY'].replace(\"N\", 0, inplace=True)\n",
    "csv_data['FLAG_OWN_REALTY'].replace(\"Y\", 1, inplace=True)\n",
    "csv_data = csv_data.fillna(\"DNE\")\n",
    "\n",
    "# Remove Outlier\n",
    "high_bound = csv_data['CNT_CHILDREN'].quantile(0.999)\n",
    "low_bound = csv_data['CNT_CHILDREN'].quantile(0.001)\n",
    "csv_data = csv_data[(csv_data['CNT_CHILDREN']>=low_bound) & (csv_data['CNT_CHILDREN']<=high_bound)]\n",
    "\n",
    "high_bound = csv_data['AMT_INCOME_TOTAL'].quantile(0.999)\n",
    "low_bound = csv_data['AMT_INCOME_TOTAL'].quantile(0.001)\n",
    "csv_data = csv_data[(csv_data['AMT_INCOME_TOTAL']>=low_bound) & (csv_data['AMT_INCOME_TOTAL']<=high_bound)]\n",
    "\n",
    "high_bound = csv_data['YEARS_EMPLOYED'].quantile(0.999)\n",
    "low_bound = csv_data['YEARS_EMPLOYED'].quantile(0.001)\n",
    "csv_data = csv_data[(csv_data['YEARS_EMPLOYED']>=low_bound) & (csv_data['YEARS_EMPLOYED']<=high_bound)]\n",
    "\n",
    "high_bound = csv_data['CNT_FAM_MEMBERS'].quantile(0.999)\n",
    "low_bound = csv_data['CNT_FAM_MEMBERS'].quantile(0.001)\n",
    "csv_data = csv_data[(csv_data['CNT_FAM_MEMBERS']>=low_bound) & (csv_data['CNT_FAM_MEMBERS']<=high_bound)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hhCM2--cYR2A",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "hhCM2--cYR2A",
    "outputId": "8837c37e-214b-43f0-b32d-a666aa134928"
   },
   "outputs": [],
   "source": [
    "credit_df = pd.read_csv('credit_record.csv')\n",
    "\n",
    "# Some Preprocessing\n",
    "credit_df['STATUS'].replace(['C', 'X', '0'], '0', inplace=True)\n",
    "credit_df['STATUS'].replace(['2','3','4','5', '1'], '1', inplace=True)\n",
    "credit_df['STATUS'] = credit_df['STATUS'].astype('int')\n",
    "credit_df_trans = credit_df.groupby('ID').agg(max).reset_index()\n",
    "credit_df_trans.drop('MONTHS_BALANCE', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77003f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(csv_data, credit_df_trans, on='ID', how='inner')\n",
    "merged_df.drop('ID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85014d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_balanced_df = merged_df.drop(merged_df[merged_df['CODE_GENDER'] < 0.5].sample(frac=0.50725, random_state=43).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02504bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feactures = [\"CODE_GENDER\", \"FLAG_OWN_CAR\", \"FLAG_OWN_REALTY\", \"NAME_INCOME_TYPE\", \"NAME_EDUCATION_TYPE\", \"NAME_FAMILY_STATUS\", \"NAME_HOUSING_TYPE\", \"FLAG_WORK_PHONE\", \"FLAG_PHONE\", \"FLAG_EMAIL\", \"OCCUPATION_TYPE\"] \n",
    "idx_categorical_feactures = list(map(lambda x: list(gender_balanced_df.columns).index(x), categorical_feactures ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f87a7d46",
   "metadata": {
    "id": "f87a7d46"
   },
   "outputs": [],
   "source": [
    "# Upsampling responsble to label to solve imbalanced learn\n",
    "X = gender_balanced_df[gender_balanced_df.columns[:-1]]\n",
    "y = gender_balanced_df[gender_balanced_df.columns[-1:]]\n",
    "oversample = SMOTENC(idx_categorical_feactures, random_state = 44)\n",
    "X_over, y_over = oversample.fit_resample(X, y)\n",
    "gender_status_balanced_df = pd.concat([X_over, y_over],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0200ba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle & Split in to input and label\n",
    "gender_status_balanced_df = sklearn.utils.shuffle(gender_status_balanced_df, random_state = 1)\n",
    "gender_status_balanced_df = gender_status_balanced_df.reset_index(drop = True)\n",
    "\n",
    "input_df = gender_status_balanced_df[gender_status_balanced_df.columns[:-1]]\n",
    "label_df = gender_status_balanced_df[gender_status_balanced_df.columns[-1:]]\n",
    "dummy_input_df = pd.get_dummies(input_df)\n",
    "\n",
    "# Normalize Input\n",
    "dummy_input_df=(dummy_input_df-dummy_input_df.min())/(dummy_input_df.max()-dummy_input_df.min())\n",
    "\n",
    "# Concat\n",
    "final_df = pd.concat([dummy_input_df, label_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d9c63df",
   "metadata": {
    "id": "5d9c63df"
   },
   "outputs": [],
   "source": [
    "# Merge & Zero out some colume\n",
    "df_value = final_df.values\n",
    "\n",
    "merge_occupy = False\n",
    "\n",
    "if merge_occupy:\n",
    "    for pairs in [[43, 35]]:\n",
    "        x, y = pairs \n",
    "        df_value[:,x] += df_value[:, y]\n",
    "        df_value[:, y] = np.zeros(df_value[:, y].shape)\n",
    "        \n",
    "# Split to training and test set\n",
    "train_set = df_value[:-4000]\n",
    "test_set = df_value[-4000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ZwKLHf1ZxiI",
   "metadata": {
    "id": "4ZwKLHf1ZxiI"
   },
   "outputs": [],
   "source": [
    "class InferDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.input = torch.tensor(data[:,1:-1], dtype=torch.float32).to(device)\n",
    "        self.fraud = torch.tensor(data[:,-1:], dtype=torch.float32).to(device)\n",
    "        self.gender = torch.tensor(data[:, 0:1], dtype=torch.float32).to(device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.input.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input[idx], self.fraud[idx], self.gender[idx]\n",
    "\n",
    "train_loader = DataLoader(InferDataset(train_set), batch_size = 64)\n",
    "test_loader  = DataLoader(InferDataset(test_set), batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9vZVsc2jbcsW",
   "metadata": {
    "id": "9vZVsc2jbcsW"
   },
   "outputs": [],
   "source": [
    "class InferNet(torch.nn.Module):\n",
    "    def __init__(self, input_dim = 0):\n",
    "        super(InferNet, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(input_dim, 1024)\n",
    "        self.linear2 = torch.nn.Linear(1024, 1024)\n",
    "        self.linear3 = torch.nn.Linear(1024, 1)\n",
    "        self.activation = torch.nn.LeakyReLU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "        torch.nn.init.zeros_(self.linear1.weight)\n",
    "        torch.nn.init.zeros_(self.linear2.weight)\n",
    "        torch.nn.init.zeros_(self.linear3.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        #x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.activation(x)\n",
    "        #x = self.dropout(x)\n",
    "        x = self.linear3(x)\n",
    "        #return x\n",
    "        return self.sigmoid(x) #torch.clamp(x, min=0, max=1)\n",
    "\n",
    "# Calculate imput dim\n",
    "inpt_sample,_,_ = InferDataset(test_set)[0]\n",
    "input_dim = inpt_sample.shape[0]\n",
    "\n",
    "# Init Fraud inferer\n",
    "fraud_infer = InferNet(input_dim).to(device)\n",
    "fraud_optimizer = torch.optim.SGD(fraud_infer.parameters(), lr=0.5, momentum=0.9)  \n",
    "fraud_scheduler = torch.optim.lr_scheduler.StepLR(fraud_optimizer, step_size = 100, gamma = 0.2)\n",
    "# Init Gender Inferer\n",
    "gender_infer = InferNet(input_dim).to(device)\n",
    "gender_optimizer = torch.optim.SGD(gender_infer.parameters(), lr=0.5, momentum=0.9)\n",
    "gender_scheduler = torch.optim.lr_scheduler.StepLR(gender_optimizer, step_size = 100, gamma = 0.2)\n",
    "# Loss Function\n",
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6869dcea",
   "metadata": {
    "id": "6869dcea"
   },
   "outputs": [],
   "source": [
    "# Train Inferers\n",
    "for epoch in range(400): \n",
    "\n",
    "    fraud_running_loss = 0.0\n",
    "    gender_running_loss = 0.0\n",
    "    \n",
    "    for data in train_loader:\n",
    "        \n",
    "        inputs, frauds, genders = data\n",
    "        \n",
    "        gender_optimizer.zero_grad()\n",
    "        gender_outputs = gender_infer(inputs)\n",
    "        gender_loss = criterion(gender_outputs, genders)\n",
    "        gender_loss.backward()\n",
    "        gender_optimizer.step()\n",
    "        gender_running_loss += gender_loss.item()\n",
    "    \n",
    "        \n",
    "        fraud_optimizer.zero_grad()\n",
    "        fraud_outputs = fraud_infer(inputs)\n",
    "        fraud_loss = criterion(fraud_outputs, frauds)\n",
    "        fraud_loss.backward()\n",
    "        fraud_optimizer.step()\n",
    "        fraud_running_loss += fraud_loss.item()\n",
    "    fraud_scheduler.step()\n",
    "    gender_scheduler.step()\n",
    "    print(f'Epoch: {epoch + 1}, gender loss: {gender_running_loss:.16f}, fraud loss: {fraud_running_loss:.16f}')\n",
    "    \n",
    "\n",
    "print('Finished Inferer Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bd0427c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9bd0427c",
    "outputId": "73c64418-b443-4c3c-d2be-aaaaf1a4f4e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 4000 cases: 96.175 %\n",
      "Number of Wrong Prediction: Actually Famele: 81, Actully Male: 72\n"
     ]
    }
   ],
   "source": [
    "# Gender Inferer Accuracy Test\n",
    "correct = 0\n",
    "total = 0\n",
    "f_total_wrong = 0\n",
    "m_total_wrong = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for data in test_loader:\n",
    "      \n",
    "        inputs, _, genders = data\n",
    "        \n",
    "        outputs = gender_infer(inputs)\n",
    "        \n",
    "        predicted = torch.round(torch.clamp(outputs, min=0, max=1))\n",
    "        #print(predicted.shape, genders.shape)\n",
    "        \n",
    "        f_total_wrong += (torch.logical_and(genders == 0, predicted == 1)).sum().item()\n",
    "        m_total_wrong += (torch.logical_and(genders == 1, predicted == 0)).sum().item()\n",
    "\n",
    "        total += genders.size(0)\n",
    "        correct += (predicted == genders).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 4000 cases: {100 * correct / total} %')\n",
    "print(f\"Number of Wrong Prediction: Actually Famele: {f_total_wrong}, Actully Male: {m_total_wrong}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4VaoNogJZuzw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4VaoNogJZuzw",
    "outputId": "053e97d3-4fab-4367-a848-41d589e7f3a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 4000 cases: 89.575 %\n",
      "Female False Positive: 111\n",
      "Female False Negative: 95\n",
      "Female True Positive: 863\n",
      "Female True Negative: 798\n",
      "Male False Positive: 108\n",
      "Male False Negative: 103\n",
      "Male True Positive: 909\n",
      "Male True Negative: 1013\n"
     ]
    }
   ],
   "source": [
    "# Fraud Inferer Accuracy Test\n",
    "correct = 0\n",
    "total = 0\n",
    "f_fp_total = 0 # Female False Positive\n",
    "f_fn_total = 0\n",
    "m_fp_total = 0\n",
    "m_fn_total = 0\n",
    "f_tp_total = 0 # Female True Positive\n",
    "f_tn_total = 0\n",
    "m_tp_total = 0\n",
    "m_tn_total = 0\n",
    "with torch.no_grad():\n",
    "\n",
    "    for data in test_loader:\n",
    "        \n",
    "        inputs, frauds, genders = data\n",
    "        outputs = fraud_infer(inputs)\n",
    "        predicted = torch.round(torch.clamp(outputs, min=0, max=1))\n",
    "        f_fp_total += torch.logical_and(genders == 0, predicted > frauds).sum().item() \n",
    "        f_fn_total += torch.logical_and(genders == 0, predicted < frauds).sum().item() \n",
    "        f_tp_total += torch.logical_and(genders == 0, torch.logical_and(predicted == frauds, frauds == 0)).sum().item() \n",
    "        f_tn_total += torch.logical_and(genders == 0, torch.logical_and(predicted == frauds, frauds == 1)).sum().item() \n",
    "        \n",
    "        m_fp_total += torch.logical_and(genders == 1, predicted > frauds).sum().item() \n",
    "        m_fn_total += torch.logical_and(genders == 1, predicted < frauds).sum().item() \n",
    "        m_tp_total += torch.logical_and(genders == 1, torch.logical_and(predicted == frauds, frauds == 0)).sum().item()\n",
    "        m_tn_total += torch.logical_and(genders == 1, torch.logical_and(predicted == frauds, frauds == 1)).sum().item()\n",
    "\n",
    "        total += frauds.size(0)\n",
    "        correct += (predicted == frauds).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 4000 cases: {100 * correct / total} %')\n",
    "print(\"Female False Positive:\", int(f_fp_total))\n",
    "print(\"Female False Negative:\", int(f_fn_total))\n",
    "print(\"Female True Positive:\", int(f_tp_total))\n",
    "print(\"Female True Negative:\", int(f_tn_total))\n",
    "print(\"Male False Positive:\", int(m_fp_total))\n",
    "print(\"Male False Negative:\", int(m_fn_total))\n",
    "print(\"Male True Positive:\", int(m_tp_total))\n",
    "print(\"Male True Negative:\", int(m_tn_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ABojbm6I3Oan",
   "metadata": {
    "id": "ABojbm6I3Oan"
   },
   "outputs": [],
   "source": [
    "# Save Models\n",
    "if merge_occupy:\n",
    "  torch.save(gender_infer.state_dict(), \"./gender_model_merge_and_zero.pts\")\n",
    "  torch.save(fraud_infer.state_dict(), \"./fraud_model_merge_and_zero.pts\")\n",
    "else:\n",
    "  torch.save(gender_infer.state_dict(), \"./gender_model_origin.pts\")\n",
    "  torch.save(fraud_infer.state_dict(), \"./fraud_model_orogin.pts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4OxEr0A05luL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4OxEr0A05luL",
    "outputId": "0192061a-93b4-4f7d-b5ef-14948369ab89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InferNet(\n",
       "  (linear1): Linear(in_features=50, out_features=1024, bias=True)\n",
       "  (linear2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (linear3): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  (activation): LeakyReLU(negative_slope=0.01)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Models\n",
    "if merge_occupy:\n",
    "  gender_infer.load_state_dict(torch.load(\"gender_model_merge_and_zero.pts\",map_location=torch.device('cpu')))\n",
    "  fraud_infer.load_state_dict(torch.load(\"fraud_model_merge_and_zero.pts\",map_location=torch.device('cpu')))\n",
    "else:\n",
    "  gender_infer.load_state_dict(torch.load(\"gender_model_origin.pts\",map_location=torch.device('cpu')))\n",
    "  fraud_infer.load_state_dict(torch.load(\"fraud_model_orogin.pts\",map_location=torch.device('cpu')))\n",
    "\n",
    "gender_infer.to(device).eval()\n",
    "fraud_infer.to(device).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vPp_ISevxeWp",
   "metadata": {
    "id": "vPp_ISevxeWp"
   },
   "outputs": [],
   "source": [
    "# Impact Analysis\n",
    "x = torch.zeros([input_dim, input_dim]).to(device)\n",
    "d0_fraud = fraud_infer(x)\n",
    "d0_gender = gender_infer(x)\n",
    "\n",
    "for i in range(input_dim):\n",
    "  x[i][i] = 1.\n",
    "\n",
    "d1_fraud = fraud_infer(x)\n",
    "d1_gender = gender_infer(x)\n",
    "delta_fraud = d1_fraud - d0_fraud\n",
    "delta_gender = d1_gender - d0_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HObjA_uqXDXT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HObjA_uqXDXT",
    "outputId": "3bb1341d-2fd9-4ad4-eaa8-96d179515566",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print(f\"G(o_i) - G(0) \\t F(o_i) Â - F(0)  Feature Idx\\tFeature\")\n",
    "for feature, dg, df in sorted(list(zip(list(enumerate(final_df.columns[1:-1])), delta_gender, delta_fraud)), key = lambda x:x[2]):\n",
    "    print(f\"{dg.item():.6f},\\t {df.item():.8f},\\t {feature[0]+1},\\t\\t{feature[1]}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CS_497_colab_merge.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
